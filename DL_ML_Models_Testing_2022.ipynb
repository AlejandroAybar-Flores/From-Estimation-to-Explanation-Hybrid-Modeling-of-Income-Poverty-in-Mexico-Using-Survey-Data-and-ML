{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hBgQOZyBdMHs",
        "F7HRL0VWd5oN",
        "y1jTCEaHepMU",
        "xuD-fCDXfGzG",
        "XkXfHt3Hfo6w",
        "IUra40IhgdhG",
        "w5oBGVMegjKo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSjP8iFVc3lE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Configuration"
      ],
      "metadata": {
        "id": "uuOx86nTdEpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel('C:/users/a.aybarf/Downloads/BBDDpobrezaII/2022/dfMLplp22.xlsx', index_col=0)"
      ],
      "metadata": {
        "id": "05XczGMhc315"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df1)"
      ],
      "metadata": {
        "id": "theEBghkc33r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = ['plp',                 # Likely an acronym (e.g., Poverty Line Percentage) – keep as-is unless you know the meaning\\n\",\n",
        "    'urban_rural',         # 'rururb' = rural or urban\\n\",\n",
        "    'age',                 # 'edad'\\n\",\n",
        "    'sex',                 # 'sexo'\\n\",\n",
        "    'literacy',            # 'alfabetism'\\n\",\n",
        "    'trabajo_mp',\n",
        "    'food_insecurity',     # 'ins_ali' = food insecurity\\n\",\n",
        "    'hli',                 # Likely an acronym – keep as-is unless clarified\\n\",\n",
        "    'public_healthcare',   # 'segpop' = public health insurance or healthcare\\n\",\n",
        "    'medical_attention',   # 'atemed'\\n\",\n",
        "    'bank_card',           # 'tarjeta' = likely a debit/credit/bank card\\n\",\n",
        "    'electricity',  # 'disp_elect' = electronic devices availability\\n\",\n",
        "    'total_residents',     # 'tot_resid'\\n\",\n",
        "    'region',              # 'región'\\n\",\n",
        "    'connectivity',        # 'conectividad' = internet or digital connectivity\\n\",\n",
        "    'water_drainage',      # 'agua_drenaje'\\n\",\n",
        "    'household_head_edu',  # 'neducativojefe' = educational level of household head\\n\",\n",
        "    'child_labor',         # 'trabajomenores'\\n\",\n",
        "    'children',            # 'niños'\\n\",\n",
        "    'household_occupation', # 'ocupacion_hogar' = economic activity of the household\\n\",\n",
        "    'consumption expenditure',\n",
        "    'housing_tenure',\n",
        "    'basic_energy_equipment'\n",
        "   ]"
      ],
      "metadata": {
        "id": "F1Fc9IVmc35g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "77fhxc7_c37r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "Wx10Ix_2c7KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "LaDN3ZJrc7MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicialización del método de muestreo por minorías sintéticas para el balanceo del conjunto de datos de entrenamiento a generar\n",
        "\n",
        "os = SMOTE(random_state=0)\n",
        "\n",
        "#División del conjunto de datos total en conjunto de entrenamiento y conjunto de prueba a través de la regla de Pareto: 80-20\n",
        "X = df1[['urban_rural', 'age', 'sex', 'literacy',\n",
        "       'food_insecurity', 'hli', 'public_healthcare', 'medical_attention',\n",
        "       'bank_card', 'electricity', 'total_residents', 'region', 'connectivity',\n",
        "       'water_drainage', 'household_head_edu', 'child_labor', 'children',\n",
        "       'household_occupation', 'consumption expenditure', 'housing_tenure',\n",
        "       'basic_energy_equipment']]\n",
        "y = df1[['plp']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "o7j8aSU6c3-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular el intervalo de confianza del AUC mediante bootstrap\n",
        "def compute_auc_ci(y_true, y_scores, n_bootstraps=1000, alpha=0.95):\n",
        "    rng = np.random.default_rng()  # Generador de números aleatorios\n",
        "    bootstrapped_scores = []\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        # Bootstrap: muestreo con reemplazo\n",
        "        indices = rng.integers(0, len(y_true), len(y_true))\n",
        "        if len(np.unique(y_true[indices])) < 2:  # Verifica que haya al menos dos clases\n",
        "            continue\n",
        "        score = auc(*roc_curve(y_true[indices], y_scores[indices])[:2])\n",
        "        bootstrapped_scores.append(score)\n",
        "\n",
        "    # Calcula los percentiles para el intervalo de confianza\n",
        "    lower = np.percentile(bootstrapped_scores, (1 - alpha) / 2 * 100)\n",
        "    upper = np.percentile(bootstrapped_scores, (1 + alpha) / 2 * 100)\n",
        "    return lower, upper\n",
        "\n",
        "# Modificar la función de la curva ROC para incluir el CI\n",
        "def plot_roc_curve_with_ci(y_true, y_scores, title=\"ROC Curve\", n_bootstraps=1000):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    ci_lower, ci_upper = compute_auc_ci(np.array(y_true), np.array(y_scores), n_bootstraps=n_bootstraps)\n",
        "\n",
        "    # Graficar la curva ROC\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f}, 95% CI = [{ci_lower:.2f}, {ci_upper:.2f}])')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    return roc_auc, ci_lower, ci_upper"
      ],
      "metadata": {
        "id": "oUrzDxykc3_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multi_roc_curves_with_ci(models_data, title=\"ROC Curves\", label=\"a\"):\n",
        "    \"\"\"\n",
        "    Grafica múltiples curvas ROC con intervalos de confianza (95% CI).\n",
        "\n",
        "    Parámetros:\n",
        "        - models_data: Lista de tuplas [(modelo, y_true, y_scores, color, nombre del modelo)].\n",
        "        - title: Título del gráfico.\n",
        "        - label: Etiqueta en la parte superior izquierda del gráfico.\n",
        "    \"\"\"\n",
        "    # Estilo limpio con fondo blanco\n",
        "    plt.style.use('default')\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    ax = plt.gca()\n",
        "    ax.set_facecolor(\"white\")  # Fondo blanco explícito para los ejes\n",
        "\n",
        "    for model_data in models_data:\n",
        "        y_true, y_scores, color, model_name = model_data\n",
        "\n",
        "        # Calcula ROC y AUC\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Calcula el intervalo de confianza del AUC\n",
        "        ci_lower, ci_upper = compute_auc_ci(np.array(y_true), np.array(y_scores))\n",
        "\n",
        "        # Agregar la curva al gráfico\n",
        "        plt.plot(\n",
        "            fpr,\n",
        "            tpr,\n",
        "            color=color,\n",
        "            lw=2,\n",
        "            label=f'{model_name} AUC={roc_auc:.3f} (CI: {ci_lower:.3f} - {ci_upper:.3f})'\n",
        "        )\n",
        "\n",
        "    # Línea diagonal gris discontinua\n",
        "    plt.plot([0, 1], [0, 1], color='white', linestyle='--', lw=1.5)\n",
        "\n",
        "     # Línea diagonal de referencia\n",
        "    plt.plot(\n",
        "        [0, 1], [0, 1],\n",
        "        color='gray',\n",
        "        linestyle='--',\n",
        "        linewidth=1.5\n",
        "    )\n",
        "\n",
        "    # Configuración del gráfico\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('1 - Specificity', fontsize=14)\n",
        "    plt.ylabel('Sensitivity', fontsize=14)\n",
        "    plt.title(title, fontsize=10)\n",
        "    # Leyenda más compacta\n",
        "    plt.legend(\n",
        "        loc=\"lower right\",\n",
        "        fontsize=11,  # Tamaño de fuente más pequeño\n",
        "        bbox_to_anchor=(1.0, 0.0),  # Ajustar la posición de la leyenda\n",
        "        frameon=True,  # Habilitar el marco\n",
        "        shadow=False,  # Sin sombra\n",
        "        borderpad=0.5  # Espaciado interno del marco\n",
        "    )\n",
        "\n",
        "    # Etiqueta en la parte superior izquierda\n",
        "    plt.text(-0.1, 1.05, label, fontsize=16, fontweight='bold', va='center', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p-rHYsvpdBiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalAveragePooling1D, Dense, Dropout, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
      ],
      "metadata": {
        "id": "csk2LHWDBhbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "import time"
      ],
      "metadata": {
        "id": "gjJfnuTuBroe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DL Testing"
      ],
      "metadata": {
        "id": "voDQIpWBdHa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train1, X_test1, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45) #hacerle reshape a todo (train, test y validation)\n",
        "\n",
        "X_train = X_train1.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True) #dividir a y_0 y y_1\n",
        "\n",
        "Xtrainfinal1 = X_train.to_numpy()\n",
        "ytrainfinal1 = y_train.to_numpy()\n",
        "X_test1 = X_test1.to_numpy()\n",
        "y_test1 = y_test.to_numpy()\n",
        "\n",
        "X_test1=tf.reshape(X_test1,(X_test1.shape[0], X_test1.shape[1],1))"
      ],
      "metadata": {
        "id": "c1e977IsCXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize StratifiedKFold for 10-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=45)"
      ],
      "metadata": {
        "id": "dgayVNBVCXFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_learning_rate = 0.01\n",
        "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=200, decay_rate=0.9)"
      ],
      "metadata": {
        "id": "_V3v6X9cCbH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "def create_cnn_model(Xtrainfinal1):\n",
        "    model = Sequential()\n",
        "    # Capas convolucionales y de pooling\n",
        "    model.add(Conv1D(filters=120, kernel_size=3, activation='relu', input_shape=(Xtrainfinal1.shape[1], Xtrainfinal1.shape[2]), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(filters=100, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=120, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    #Capas densas\n",
        "    model.add(Dense(40, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))  # Add dropout for regularization\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy']) #sparse_categorical_crossentropy (si es que no funciona la división de y con one-hot encoding)\n",
        "    return model"
      ],
      "metadata": {
        "id": "p1M_RHoFB-Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "counter = 1\n",
        "accuracyacumulada = 0.0\n",
        "\n",
        "# Mide el tiempo de entrenamiento\n",
        "start_time = time.time()\n",
        "# Perform 10-fold cross-validation\n",
        "for train_idx, val_idx in kfold.split(Xtrainfinal1, ytrainfinal1):\n",
        "\n",
        "    dfX = pd.DataFrame(Xtrainfinal1, columns=X.columns)\n",
        "    dfy = pd.DataFrame(ytrainfinal1, columns=y.columns)\n",
        "\n",
        "    X_trainP, X_val = dfX.loc[train_idx], dfX.loc[val_idx]\n",
        "    y_trainP, y_val = dfy.loc[train_idx], dfy.loc[val_idx]\n",
        "\n",
        "    X_trainP = X_trainP.to_numpy()\n",
        "    X_val = X_val.to_numpy()\n",
        "    y_trainP = y_trainP.to_numpy()\n",
        "    y_val = y_val.to_numpy()\n",
        "\n",
        "    X_trainP=tf.reshape(X_trainP,(X_trainP.shape[0], X_trainP.shape[1],1))\n",
        "    X_val=tf.reshape(X_val,(X_val.shape[0], X_val.shape[1],1))\n",
        "\n",
        "    model = create_cnn_model(X_trainP)\n",
        "    fold_start_time = time.time()\n",
        "    history = model.fit(X_trainP, y_trainP, epochs=50, batch_size=96, validation_data=(X_val, y_val), verbose=0) #100 epochs\n",
        "    fold_end_time = time.time()\n",
        "    #history\n",
        "    #(sacarlo primero del for para probar la arquitecutra y luego incluirlo)\n",
        "\n",
        "    fold_duration = fold_end_time - fold_start_time\n",
        "    print(f\"Tiempo de entrenamiento del Fold {counter}: {fold_duration:.2f} segundos\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_val_pred = (y_val_pred > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    print(f'Validation Accuracy {counter}: {accuracy * 100:.2f}%')\n",
        "\n",
        "    counter += 1\n",
        "    accuracyacumulada += accuracy\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "        best_history = history\n",
        "        bestcm = confusion_matrix(y_val, y_val_pred)\n",
        "        best_precision = precision_score(y_val, y_val_pred)\n",
        "        bestrecall = recall_score(y_val, y_val_pred)\n",
        "        bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "        bestf1 = f1_score(y_val, y_val_pred)\n",
        "        fpr, tpr, _ = roc_curve(y_val, y_val_pred)\n",
        "        bestroc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "print(' ')\n",
        "print(f'Average Validation Accuracy: {(accuracyacumulada/10) * 100:.2f}%')\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "-7bm65lCdBke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula duración\n",
        "training_time = end_time - start_time\n",
        "print(f\"Tiempo total de entrenamiento: {training_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "CV4_eGVspnym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%')\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}%')\n",
        "print(f'Best Validation AUC: {bestroc_auc:.2f}%')"
      ],
      "metadata": {
        "id": "FqwILnEvChiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Matriz de confusión estimada\n",
        "conf_matrix = np.array([[929, 134],\n",
        "       [308, 377]])  # [FP, TN]\n",
        "\n",
        "# Reorganizar a formato: [[TP, FN], [FP, TN]]\n",
        "# Pero para seaborn, la convención es: filas = reales, columnas = predichos\n",
        "# Así que reorganizamos como:\n",
        "# [[TP, FN],    --> Positivo real\n",
        "#  [FP, TN]]    --> Negativo real\n",
        "\n",
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixRF.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "beqnrk-iChkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current learning rate from the optimizer\n",
        "current_learning_rate = tf.keras.backend.get_value(model.optimizer.learning_rate)\n",
        "print(\"Current Learning Rate:\", current_learning_rate)"
      ],
      "metadata": {
        "id": "XPpwrpiRpn03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(best_model, to_file='prueba1_best_model_cnn_modelMODELOFINALv2.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "8p15ujd8Cm91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting both training accuracy and loss in a single graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training accuracy and loss in the same graph\n",
        "plt.plot(best_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(best_history.history['loss'], label='Train Loss')\n",
        "\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('accuracy_loss_plot_best_modelMODELOFINALv2.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_jwHIODCkse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the best model\n",
        "y_test_pred = best_model.predict(X_test1)\n",
        "\n",
        "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the performance on the test set\n",
        "test_accuracy = accuracy_score(y_test1, y_test_pred)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "K5_8Nl_DCkui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "confusion = confusion_matrix(y_test1, y_test_pred)\n",
        "confusion"
      ],
      "metadata": {
        "id": "6jxNIN7sCoEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixMODELOFINALv2.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EijqRI_WpoFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test1, y_test_pred)\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test1, y_test_pred)\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test1, y_test_pred)\n",
        "# Calculate recall (sensitivity)\n",
        "recall = recall_score(y_test1, y_test_pred)\n",
        "# Calculate specificity\n",
        "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test1, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "47NF3ynnCp2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calcula el AUC y grafica la curva ROC\n",
        "def plot_roc_curve(y_true, y_scores, title=\"ROC Curve\"):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    return roc_auc\n",
        "\n",
        "# Evaluar AUC en el conjunto de validación y graficar para la última iteración del cross-validation\n",
        "y_val_scores = best_model.predict(X_val).ravel()  # Probabilidades para el conjunto de validación\n",
        "auc_val = plot_roc_curve(y_val, y_val_scores, title=\"ROC Curve (Validation Set)\")\n",
        "\n",
        "# Evaluar AUC en el conjunto de prueba\n",
        "y_test_scores = best_model.predict(X_test1).ravel()  # Probabilidades para el conjunto de prueba\n",
        "auc_test = plot_roc_curve(y_test1, y_test_scores, title=\"ROC Curve (Test Set)\")\n",
        "\n",
        "print(f'Validation AUC: {auc_val:.2f}')\n",
        "print(f'Test AUC: {auc_test:.2f}')"
      ],
      "metadata": {
        "id": "PMM5GY11CrJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Testing"
      ],
      "metadata": {
        "id": "ShnC-QkddKcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression"
      ],
      "metadata": {
        "id": "hBgQOZyBdMHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "parameters = {'solver':['newton-cg','liblinear','sag','saga']}\n",
        "clf_lr = GridSearchCV(LogisticRegression(), parameters, cv=10, n_jobs=-1,verbose=4)\n",
        "clf_lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "UWaYe0J0dBmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr.best_params_"
      ],
      "metadata": {
        "id": "SY8yMeEJdNTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr.best_score_"
      ],
      "metadata": {
        "id": "9TvN4JiwdNVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = clf_lr.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "ShXfdgfBdhiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "Fc_2h3TvdhkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(clf_lr.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "DbLDYRfjdhmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "bestcm = confusion_matrix(y_train, clf_lr.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, clf_lr.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, clf_lr.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, clf_lr.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, clf_lr.best_estimator_.predict(X_train))\n",
        "auclr = round(metrics.roc_auc_score(y_train, clf_lr.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%') #sensitivity\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}')\n",
        "print(f'Best Validation AUC: {auclr:.2f}')"
      ],
      "metadata": {
        "id": "kvz7YguadkV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,clf_lr.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "W87x4WkqdkX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixLRTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tlcTW7tRdkZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(clf_lr.best_estimator_, 'mejor_modeloLR.pkl')"
      ],
      "metadata": {
        "id": "s7Bkm1K8dnh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloLR = clf_lr.best_estimator_\n",
        "predictionslr = modeloLR.predict(X_test)\n",
        "targetlr=np.array(y_test)\n",
        "confusionlr = confusion_matrix(targetlr, predictionslr)\n",
        "print(confusionlr)"
      ],
      "metadata": {
        "id": "vGQtw4Lqdnj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmlr = confusion_matrix(targetlr,predictionslr)\n",
        "# Calculate accuracy\n",
        "accuracylr = accuracy_score(targetlr,predictionslr)\n",
        "# Calculate precision\n",
        "precisionlr = precision_score(targetlr,predictionslr)\n",
        "# Calculate recall (sensitivity)\n",
        "recalllr = recall_score(targetlr,predictionslr)\n",
        "# Calculate specificity\n",
        "specificitylr = cmlr[0, 0] / (cmlr[0, 0] + cmlr[0, 1])\n",
        "# Calculate F1-score\n",
        "f1lr = f1_score(targetlr,predictionslr)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracylr:.4f}\")\n",
        "print(f\"Precision: {precisionlr:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recalllr:.4f}\")\n",
        "print(f\"Specificity: {specificitylr:.4f}\")\n",
        "print(f\"F1-score: {f1lr:.4f}\")"
      ],
      "metadata": {
        "id": "WQ449WFLdnle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetlr,predictionslr))"
      ],
      "metadata": {
        "id": "GX1Rbcx0dnns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionlr, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixLRTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yi8ji_Ixduht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, clf_lr.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'LR'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCLRTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q9hwWFPVduj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetlr, modeloLR.predict_proba(X_test)[:, 1], 'red', 'LR'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCLRTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZSJh3UDdNXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "F7HRL0VWd5oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100,110,120,130,140,150,160,170,180,190,200],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8,9,10,11,12],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "grid_searchRF = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, n_jobs=-1,verbose=4)\n",
        "grid_searchRF.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "PNwpxJQod5Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchRF.best_score_"
      ],
      "metadata": {
        "id": "kRkFCZPHd5Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchRF.best_params_"
      ],
      "metadata": {
        "id": "_GCX9ztmd5JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = grid_searchRF.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "1NQLsW4sd5Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchRF.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "WpHUx_tMd5Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(grid_searchRF.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "GEHUD8Wyd5Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestcm = confusion_matrix(y_train, grid_searchRF.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, grid_searchRF.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, grid_searchRF.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, grid_searchRF.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, grid_searchRF.best_estimator_.predict(X_train))\n",
        "aucrf = round(metrics.roc_auc_score(y_train, grid_searchRF.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%')\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}%')\n",
        "print(f'Best Validation AUC: {aucrf:.2f}')"
      ],
      "metadata": {
        "id": "LuTU_br-d5R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,grid_searchRF.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "AyRq8kE7d5UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixRFTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "utMSwuMWee74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(grid_searchRF.best_estimator_, 'mejor_modeloRF.pkl')"
      ],
      "metadata": {
        "id": "DUfwX5HJee9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloRF = grid_searchRF.best_estimator_\n",
        "predictionsRF = modeloRF.predict(X_test)\n",
        "targetRF=np.array(y_test)\n",
        "confusionRF = confusion_matrix(targetRF, predictionsRF)\n",
        "print(confusionRF)"
      ],
      "metadata": {
        "id": "5NayHp59ee_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmRF = confusion_matrix(targetRF,predictionsRF)\n",
        "# Calculate accuracy\n",
        "accuracyRF = accuracy_score(targetRF,predictionsRF)\n",
        "# Calculate precision\n",
        "precisionRF = precision_score(targetRF,predictionsRF)\n",
        "# Calculate recall (sensitivity)\n",
        "recallRF = recall_score(targetRF,predictionsRF)\n",
        "# Calculate specificity\n",
        "specificityRF = cmRF[0, 0] / (cmRF[0, 0] + cmRF[0, 1])\n",
        "# Calculate F1-score\n",
        "f1RF = f1_score(targetRF,predictionsRF)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracyRF:.4f}\")\n",
        "print(f\"Precision: {precisionRF:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recallRF:.4f}\")\n",
        "print(f\"Specificity: {specificityRF:.4f}\")\n",
        "print(f\"F1-score: {f1RF:.4f}\")"
      ],
      "metadata": {
        "id": "RecxxBoEc4CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetRF,predictionsRF))"
      ],
      "metadata": {
        "id": "UdLUFYGUejZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionRF, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixRFTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KntDm8xMeja5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, grid_searchRF.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'RF'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCRFTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v-os9nCzejep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetRF, modeloRF.predict_proba(X_test)[:, 1], 'red', 'RF'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCRFTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "53FFQQ6Bejgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree"
      ],
      "metadata": {
        "id": "y1jTCEaHepMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_searchdt = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10, n_jobs=-1,verbose=4)\n",
        "grid_searchdt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HRonUjqBejiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchDT = grid_searchdt"
      ],
      "metadata": {
        "id": "detzXaJ1espj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchDT.best_score_"
      ],
      "metadata": {
        "id": "qU4asXJ_esrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchDT.best_params_"
      ],
      "metadata": {
        "id": "L6dchwoxesuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = grid_searchDT.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "PNUduAojeswZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_searchDT.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "JB7e3mgvesyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(grid_searchDT.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "AmlfJxUwes1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestcm = confusion_matrix(y_train, grid_searchDT.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, grid_searchDT.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, grid_searchDT.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, grid_searchDT.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, grid_searchDT.best_estimator_.predict(X_train))\n",
        "aucrf = round(metrics.roc_auc_score(y_train, grid_searchDT.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%')\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}%')\n",
        "print(f'Best Validation AUC: {aucrf:.2f}')"
      ],
      "metadata": {
        "id": "j3GL7yPres28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,grid_searchDT.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "HoAvTG9Xe63y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixDTTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NhLRpt8he65j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(grid_searchDT.best_estimator_, 'mejor_modeloDT.pkl')"
      ],
      "metadata": {
        "id": "8iInK_sIes5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloDT = grid_searchDT.best_estimator_\n",
        "predictionsDT = modeloDT.predict(X_test)\n",
        "targetDT=np.array(y_test)\n",
        "confusionDT = confusion_matrix(targetDT, predictionsDT)\n",
        "print(confusionDT)"
      ],
      "metadata": {
        "id": "AeC2kvcKetQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmDT = confusion_matrix(targetDT,predictionsDT)\n",
        "# Calculate accuracy\n",
        "accuracyDT = accuracy_score(targetDT,predictionsDT)\n",
        "# Calculate precision\n",
        "precisionDT = precision_score(targetDT,predictionsDT)\n",
        "# Calculate recall (sensitivity)\n",
        "recallDT = recall_score(targetDT,predictionsDT)\n",
        "# Calculate specificity\n",
        "specificityDT = cmDT[0, 0] / (cmDT[0, 0] + cmDT[0, 1])\n",
        "# Calculate F1-score\n",
        "f1DT = f1_score(targetDT,predictionsDT)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracyDT:.4f}\")\n",
        "print(f\"Precision: {precisionDT:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recallDT:.4f}\")\n",
        "print(f\"Specificity: {specificityDT:.4f}\")\n",
        "print(f\"F1-score: {f1DT:.4f}\")"
      ],
      "metadata": {
        "id": "K24q-zgCfAgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetDT,predictionsDT))"
      ],
      "metadata": {
        "id": "iOk7UapVfAiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionDT, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixDTTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EQ7mB0sofAkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, grid_searchDT.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'DT'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCDTTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rUbdFcDlfAmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetDT, modeloDT.predict_proba(X_test)[:, 1], 'red', 'DT'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCDTTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9YOXgfC1ejlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ERT"
      ],
      "metadata": {
        "id": "xuD-fCDXfGzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [False, True],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_search_ert = GridSearchCV(\n",
        "    ExtraTreesClassifier(),\n",
        "    param_grid,\n",
        "    cv=10,\n",
        "    n_jobs=-1,\n",
        "    verbose=4\n",
        ")\n",
        "\n",
        "grid_search_ert.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_6mHSPtdfGNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_ert.best_params_"
      ],
      "metadata": {
        "id": "OO7jXXaCfSKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_ert.best_score_"
      ],
      "metadata": {
        "id": "_zlha8WifSMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = grid_search_ert.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "9xfu7pmAfSOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_ert.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "kZs-D2fufSUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(grid_search_ert.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "X2EZCrnnfSWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestcm = confusion_matrix(y_train, grid_search_ert.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, grid_search_ert.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, grid_search_ert.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, grid_search_ert.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, grid_search_ert.best_estimator_.predict(X_train))\n",
        "auclr = round(metrics.roc_auc_score(y_train, grid_search_ert.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%') #sensitivity\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}')\n",
        "print(f'Best Validation AUC: {auclr:.2f}')"
      ],
      "metadata": {
        "id": "HP3mGAPAfcfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,grid_search_ert.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "dBKfmyWKfcg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixERTTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nUL8RyNmfSYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(grid_search_ert.best_estimator_, 'mejor_modeloERT.pkl')"
      ],
      "metadata": {
        "id": "VbEFzS78fSbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloERT = grid_search_ert.best_estimator_\n",
        "predictionsERT = modeloERT.predict(X_test)\n",
        "targetERT=np.array(y_test)\n",
        "confusionERT = confusion_matrix(targetERT, predictionsERT)\n",
        "print(confusionERT)"
      ],
      "metadata": {
        "id": "02_66eLefSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmERT = confusion_matrix(targetERT, predictionsERT)\n",
        "# Calculate accuracy\n",
        "accuracyERT = accuracy_score(targetERT, predictionsERT)\n",
        "# Calculate precision\n",
        "precisionERT = precision_score(targetERT, predictionsERT)\n",
        "# Calculate recall (sensitivity)\n",
        "recallERT = recall_score(targetERT, predictionsERT)\n",
        "# Calculate specificity\n",
        "specificityERT = cmERT[0, 0] / (cmERT[0, 0] + cmERT[0, 1])\n",
        "# Calculate F1-score\n",
        "f1ERT = f1_score(targetERT, predictionsERT)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracyERT:.4f}\")\n",
        "print(f\"Precision: {precisionERT:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recallERT:.4f}\")\n",
        "print(f\"Specificity: {specificityERT:.4f}\")\n",
        "print(f\"F1-score: {f1ERT:.4f}\")"
      ],
      "metadata": {
        "id": "Dd5Q_sdRfiKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetERT,predictionsERT))"
      ],
      "metadata": {
        "id": "nCDFcr7afiPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionERT, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixERTTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ip61MqQufiSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, grid_search_ert.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'ERT'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCERTTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Bzs5WkOfiW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetERT, modeloERT.predict_proba(X_test)[:, 1], 'red', 'ERT'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCERTTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7JKewL03fig0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "XkXfHt3Hfo6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBOOST\n",
        "\n",
        "estimator = XGBClassifier(booster='gbtree',\n",
        "    objective= 'binary:logistic',\n",
        "    nthread=4,\n",
        "    seed=42\n",
        ")\n",
        "parameters = {\n",
        "    'max_depth': range (2, 10, 1),\n",
        "    'n_estimators': range(20, 220, 20),\n",
        "    'learning_rate': [0.1, 0.01, 0.05, 0.075],\n",
        "    'min_split_loss': np.linspace(0, 1, 6),\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=estimator,\n",
        "    param_grid=parameters,\n",
        "    scoring = 'accuracy',\n",
        "    cv=10, n_jobs=-1,\n",
        "    verbose=4\n",
        ")\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tcDLNQ3kf5jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "TCeDCdYEf5lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_score_"
      ],
      "metadata": {
        "id": "dPix-cGLf5rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = grid_search.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "AQcnWEGcf5tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "3HcUvVYtf5vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(grid_search.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "Uwzi7T5IfnUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestcm = confusion_matrix(y_train, grid_search.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, grid_search.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, grid_search.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, grid_search.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, grid_search.best_estimator_.predict(X_train))\n",
        "auclr = round(metrics.roc_auc_score(y_train, grid_search.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%') #sensitivity\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}')\n",
        "print(f'Best Validation AUC: {auclr:.2f}')"
      ],
      "metadata": {
        "id": "6Je3efergEtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,grid_search.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "M3bsdSPYgEvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixXGBOOSTTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ar26ZXTgEw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(grid_search.best_estimator_, 'mejor_modeloXGBOOST.pkl')"
      ],
      "metadata": {
        "id": "gkPgpdD9gEyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloXgboost = grid_search.best_estimator_\n",
        "predictionsXGBOOST = modeloXgboost.predict(X_test)\n",
        "targetXGBOOST=np.array(y_test)\n",
        "confusionXGBOOST = confusion_matrix(targetXGBOOST, predictionsXGBOOST)\n",
        "print(confusionXGBOOST)"
      ],
      "metadata": {
        "id": "VHaeRR1EgE3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmXGBOOST = confusion_matrix(targetXGBOOST,predictionsXGBOOST)\n",
        "# Calculate accuracy\n",
        "accuracyXGBOOST = accuracy_score(targetXGBOOST,predictionsXGBOOST)\n",
        "# Calculate precision\n",
        "precisionXGBOOST = precision_score(targetXGBOOST,predictionsXGBOOST)\n",
        "# Calculate recall (sensitivity)\n",
        "recallXGBOOST = recall_score(targetXGBOOST,predictionsXGBOOST)\n",
        "# Calculate specificity\n",
        "specificityXGBOOST = cmXGBOOST[0, 0] / (cmXGBOOST[0, 0] + cmXGBOOST[0, 1])\n",
        "# Calculate F1-score\n",
        "f1XGBOOST = f1_score(targetXGBOOST,predictionsXGBOOST)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracyXGBOOST:.4f}\")\n",
        "print(f\"Precision: {precisionXGBOOST:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recallXGBOOST:.4f}\")\n",
        "print(f\"Specificity: {specificityXGBOOST:.4f}\")\n",
        "print(f\"F1-score: {f1XGBOOST:.4f}\")"
      ],
      "metadata": {
        "id": "hGmN--cOfGPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetXGBOOST,predictionsXGBOOST))"
      ],
      "metadata": {
        "id": "M60WijKAc4D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionXGBOOST, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixXGBOOSTTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZUzwKOtLc4GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, grid_search.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'XGBoost'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCXGBoostTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wNs4A6BEgTwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetXGBOOST, modeloXgboost.predict_proba(X_test)[:, 1], 'red', 'XGBoost'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCXGBoostTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wdOAFlqsgTyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ANN"
      ],
      "metadata": {
        "id": "FClyyO0fgWcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'activation':['logistic','relu'],'solver': ['lbfgs', 'sgd', 'adam'], 'max_iter': [250,500,750,1000], 'hidden_layer_sizes': np.arange(2,26,1), 'momentum':[0.4,0.5,0.6,0.7,0.8,0.9],'learning_rate': ['constant', 'adaptive'],'learning_rate_init':[0.1,0.5,0.01]}\n",
        "clf_RNA = GridSearchCV(MLPClassifier(), parameters, cv=10, n_jobs=-1, verbose=4)\n",
        "clf_RNA.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "p7iHPDiegT0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RNA.best_params_"
      ],
      "metadata": {
        "id": "JUlX2jZchNjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RNA.best_score_"
      ],
      "metadata": {
        "id": "xrRfFG4mhNlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener todos los promedios de accuracy por combinación de parámetros\n",
        "all_mean_accuracies = clf_RNA.cv_results_['mean_test_score']\n",
        "\n",
        "# Calcular el promedio general de esos promedios\n",
        "overall_cv_accuracy = all_mean_accuracies.mean()\n",
        "\n",
        "print(f\"Accuracy promedio total de todos los CVs: {overall_cv_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "mymiwJydhNnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_RNA.cv_results_['mean_fit_time']"
      ],
      "metadata": {
        "id": "xOZ8VqlMhTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_fit_time = sum(clf_RNA.cv_results_['mean_fit_time']) * 10\n",
        "print(f\"Tiempo estimado total de entrenamiento: {total_fit_time:.2f} segundos\")"
      ],
      "metadata": {
        "id": "UNmiVybQhTmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestcm = confusion_matrix(y_train, clf_RNA.best_estimator_.predict(X_train))\n",
        "best_accuracy = accuracy_score(y_train, clf_RNA.best_estimator_.predict(X_train))\n",
        "best_precision = precision_score(y_train, clf_RNA.best_estimator_.predict(X_train))\n",
        "bestrecall = recall_score(y_train, clf_RNA.best_estimator_.predict(X_train))\n",
        "bestspecificity = bestcm[0, 0] / (bestcm[0, 0] + bestcm[0, 1])\n",
        "bestf1 = f1_score(y_train, clf_RNA.best_estimator_.predict(X_train))\n",
        "auclr = round(metrics.roc_auc_score(y_train, clf_RNA.best_estimator_.predict(X_train)), 4)\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
        "print(f'Best Validation Precision: {best_precision * 100:.2f}%')\n",
        "print(f'Best Validation Recall: {bestrecall * 100:.2f}%') #sensitivity\n",
        "print(f'Best Validation Specificity: {bestspecificity * 100:.2f}%')\n",
        "print(f'Best Validation F1: {bestf1:.2f}')\n",
        "print(f'Best Validation AUC: {auclr:.2f}')"
      ],
      "metadata": {
        "id": "caYGrhjIhVRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train,clf_RNA.best_estimator_.predict(X_train)))"
      ],
      "metadata": {
        "id": "7P2pENMFhTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(bestcm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixANNTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fcAEqSZ2hNon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo\n",
        "joblib.dump(clf_RNA.best_estimator_, 'mejor_modeloANN.pkl')"
      ],
      "metadata": {
        "id": "2aeVGkSChNqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN = clf_RNA.best_estimator_\n",
        "predictionsANN = modelNN.predict(X_test)\n",
        "targetANN=np.array(y_test)\n",
        "confusionANN = confusion_matrix(targetANN, predictionsANN)\n",
        "print(confusionANN)"
      ],
      "metadata": {
        "id": "SkMFtN4NhZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cmAN = confusion_matrix(targetANN,predictionsANN)\n",
        "# Calculate accuracy\n",
        "accuracyAN = accuracy_score(targetANN,predictionsANN)\n",
        "# Calculate precision\n",
        "precisionAN = precision_score(targetANN,predictionsANN)\n",
        "# Calculate recall (sensitivity)\n",
        "recallAN= recall_score(targetANN,predictionsANN)\n",
        "# Calculate specificity\n",
        "specificityAN = cmAN[0, 0] / (cmAN[0, 0] + cmAN[0, 1])\n",
        "# Calculate F1-score\n",
        "f1AN = f1_score(targetANN,predictionsANN)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracyAN:.4f}\")\n",
        "print(f\"Precision: {precisionAN:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recallAN:.4f}\")\n",
        "print(f\"Specificity: {specificityAN:.4f}\")\n",
        "print(f\"F1-score: {f1AN:.4f}\")"
      ],
      "metadata": {
        "id": "otnrozAlhZIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targetANN,predictionsANN))"
      ],
      "metadata": {
        "id": "YQBXcg16hZbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix using seaborn\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusionANN, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            annot_kws={\"size\": 15}, xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('confusionmatrixANNTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TinLMeuohcDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, clf_RNA.best_estimator_.predict_proba(X_train)[:, 1], 'red', 'ANN'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCANNTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JiQjQ_DOhcFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "models_data2 = [\n",
        "    #(y_val, y_val_scores, 'purple', \"1D-CNN\"),\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetlr, clf_RNA.predict_proba(X_test)[:, 1], 'red', 'ANN'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvaROCANNTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r04JKVr9gYZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curves"
      ],
      "metadata": {
        "id": "IUra40IhgdhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso (sustituir con tus datos reales)\n",
        "models_data2 = [\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (y_train, modeloLR.predict_proba(X_train)[:, 1], 'red', 'LR'),\n",
        "    (y_train, modeloRF.predict_proba(X_train)[:, 1], 'blue', 'RF'),\n",
        "    (y_train, modeloDT.predict_proba(X_train)[:, 1], 'orange', 'DT'),\n",
        "    (y_train, modeloERT.predict_proba(X_train)[:, 1], 'yellow', 'ERT'),\n",
        "    (y_train, modeloXgboost.predict_proba(X_train)[:, 1], 'green', 'XGBoost'),\n",
        "    (y_train, modeloGBM.predict_proba(X_train)[:, 1], 'purple', 'GBM'),\n",
        "    (y_train, modeloAdaboost.predict_proba(X_train)[:, 1], 'black', 'Adaboost'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvasROCTrain.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03crHYDGgYbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso (sustituir con tus datos reales)\n",
        "models_data2 = [\n",
        "    # Agregar más modelos si es necesario: (y_true, y_scores, color, nombre del modelo)\n",
        "    (targetlr, modeloLR.predict_proba(X_test)[:, 1], 'red', 'LR'),\n",
        "    (targetRF, modeloRF.predict_proba(X_test)[:, 1], 'blue', 'RF'),\n",
        "    (targetDT, modeloDT.predict_proba(X_test)[:, 1], 'orange', 'DT'),\n",
        "    (targetERT, modeloERT.predict_proba(X_test)[:, 1], 'yellow', 'ERT'),\n",
        "    (targetXGBOOST, modeloXgboost.predict_proba(X_test)[:, 1], 'green', 'XGBoost'),\n",
        "    (targetGBM, modeloGBM.predict_proba(X_test)[:, 1], 'purple', 'GBM'),\n",
        "    (targetAdaboost, modeloAdaboost.predict_proba(X_test)[:, 1], 'black', 'Adaboost'),\n",
        "]\n",
        "\n",
        "plot_multi_roc_curves_with_ci(models_data2, title=\"ROC Curves\", label=\"a\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('CurvasROCTest.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RkxM1hWUgYdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shapley Values"
      ],
      "metadata": {
        "id": "w5oBGVMegjKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample = shap.sample(X_test,500)"
      ],
      "metadata": {
        "id": "4VoPvV0SgYfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample.head(10)"
      ],
      "metadata": {
        "id": "JfW0-WzHgYhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir el tensor de TensorFlow a un array de NumPy\n",
        "X_test_reshaped = X_test1.numpy()"
      ],
      "metadata": {
        "id": "Nrs3vPa3grhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Inicializar el explainer SHAP\n",
        "explainer = shap.DeepExplainer(best_model, X_test_reshaped)"
      ],
      "metadata": {
        "id": "6-j5CrGRgYjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrate de que los shap_values sean bidimensionales\n",
        "shap_values2 = shap_values.reshape(shap_values.shape[0], -1)"
      ],
      "metadata": {
        "id": "AKSsoMG4gYle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explanation= shap.Explanation(values=shap_values2,\n",
        "                             data=X_test_reshaped,\n",
        "                             feature_names=X.columns)\n",
        "shap.plots.bar(explanation, max_display=11)"
      ],
      "metadata": {
        "id": "2Ilf7bOVgYng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Opcional) Crear un summary plot para mostrar todas las contribuciones\n",
        "shap.summary_plot(shap_values2, X_test_original)"
      ],
      "metadata": {
        "id": "Ilsy0Q9XgYpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(explanation[0], max_display=11) #Problemas Mentales"
      ],
      "metadata": {
        "id": "29Nq1A6rgZB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(explanation[1], max_display=11) #Sin Problemas Mentales"
      ],
      "metadata": {
        "id": "USeCKPewc4IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D30xw434c4KX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}